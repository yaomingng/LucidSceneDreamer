pretrained_weight: ./scenedreamer_released.pt

# Define the dummy dataset class *within* the config.
data_module:
  __init__:
    from torch.utils.data import Dataset
    class DummyDataset(Dataset):
      def __init__(self, cfg, is_inference=False, is_test=False):
          self.length = 100 # Just needs *some* length.
          self.output_height = cfg.gen.crop_size[0] + cfg.gen.pad
          self.output_width = cfg.gen.crop_size[1] + cfg.gen.pad

      def __len__(self):
          return self.length

      def __getitem__(self, index):
            # Return dummy tensors of the correct *shape*.  The content doesn't matter.
            # We only need to return the data needed by sample_camera and by the forward pass.
            return {
              'images': torch.randn(1, 3, self.output_height, self.output_width), # dummy
              'label':  torch.randn(1, 1, self.output_height, self.output_width), # dummy
              }

inference_args:
    camera_mode: 4
    cam_maxstep: 40
    resolution_hw: [540, 960]
    num_samples: 40
    cam_ang: 72

image_save_iter: 5000
snapshot_save_epoch: 5
snapshot_save_iter: 10000
max_epoch: 400
logging_iter: 10

trainer:
    type: imaginaire.trainers.lucidscenedreamer # Changed trainer type
    model_average_config:
        enabled: False
    amp_config:
        enabled: False # Adjust as needed
    loss_weight:
        sds: 1.0 # Add SDS loss weight (TUNE THIS! Start low, e.g., 0.001)
    init:
        type: xavier
        gain: 0.02

    image_to_tensorboard: True
    distributed_data_parallel_params:
        find_unused_parameters: False
        broadcast_buffers: False

gen_opt:
    type: adam
    lr: 0.0001 # You might need to tune this.  SDS can be sensitive.
    eps: 1.e-7
    adam_beta1: 0.
    adam_beta2: 0.999
    lr_policy:
        iteration_mode: False
        type: step
        step_size: 400
        gamma: 0.1
    param_groups:
        world_encoder:
            lr: 0.0005
        hash_encoder:
            lr: 0.0001
        render_net:
            lr: 0.0001
        sky_net:
            lr: 0.0001
        style_net:
            lr: 0.0001
        style_encoder:
            lr: 0.0001
        denoiser:
            lr: 0.0001

gen:
    type: imaginaire.generators.lucidscenedreamer # Changed generator type
    pcg_dataset_path: ./data/terrain_cache
    pcg_cache: True
    scene_size: 2048

    blk_feat_dim: 64

    pe_lvl_feat: 4
    pe_incl_orig_feat: False
    pe_no_pe_feat_dim: 40
    pe_lvl_raydir: 0
    pe_incl_orig_raydir: False
    style_dims: 128 # Set to 0 to disable style.
    interm_style_dims: 256
    final_feat_dim: 64
    pad: 6

    # ======== Sky network ========
    pe_lvl_raydir_sky: 5
    pe_incl_orig_raydir_sky: True

    stylenet_model: StyleMLP # keeping this optional
    stylenet_model_kwargs:
        normalize_input: True
        num_layers: 5

    mlp_model: RenderMLP
    mlp_model_kwargs:
        use_seg: True

    # ======== Ray Casting Params ========
    num_blocks_early_stop: 6
    num_samples: 24 # Decrease it if you got OOM on lowend GPU
    sample_depth: 3 # Stop the ray after certain depth
    coarse_deterministic_sampling: False
    sample_use_box_boundaries: False # Including voxel boundaries into the sample

    # ======== Blender ========
    raw_noise_std: 0.0
    dists_scale: 0.25
    clip_feat_map: True
    # Prevent sky from leaking to the foreground.
    keep_sky_out: True
    keep_sky_out_avgpool: True
    sky_global_avgpool: True

    # ======== Label translator ========
    reduced_label_set: True
    use_label_smooth: True
    use_label_smooth_real: True
    use_label_smooth_pgt: True
    label_smooth_dia: 11

    # ======== Camera sampler ========
    camera_sampler_type: "traditional"
    cam_res: [360, 640] # Camera resolution before cropping.
    crop_size: [256, 256] # Actual crop size is crop_size+pad. It should generally match random_crop_h_w in dataloader.
    camera_min_entropy: 0.75
    camera_rej_avg_depth: 2.0

# Data options.  Using a custom, in-line dataset definition.
data:
    type: ${data_module}.DummyDataset # Use a custom, inline definition
    num_workers: 0 # No workers needed for this dummy dataset.
    train:
        batch_size: 1
        augmentations: {} # No augmentations needed.
        prompt:
            - "A green field with a blue sky."
    val:
        batch_size: 1
        augmentations: {}

test_data:
    type: imaginaire.datasets.dummy
    num_workers: 0

sds_loss:
    pretrained_model_name_or_path: "" # Add the path to your Stable Diffusion model here.
